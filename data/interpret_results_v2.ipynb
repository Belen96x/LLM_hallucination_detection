{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d76fdc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Rutas correctas\n",
    "file_paths = [\n",
    "    \"output_v2_gemma3.csv\",\n",
    "    \"output_v2_llama3.csv\",\n",
    "    \"output_v2_qwen.csv\"\n",
    "]\n",
    "\n",
    "# Cargar y etiquetar cada archivo\n",
    "def load_and_tag_model(file_path):\n",
    "    filename = os.path.basename(file_path)\n",
    "    model_name = filename.split(\"output_\")[1].replace(\".csv\", \"\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    df[\"model\"] = model_name\n",
    "    return df\n",
    "\n",
    "dfs = [load_and_tag_model(fp) for fp in file_paths]\n",
    "df_all = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3754e0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             model ground_truth_classification  accuracy_percent\n",
      "0         gemma22b          1_No_hallucination             100.0\n",
      "1         gemma22b       2_Small_hallucination             100.0\n",
      "2         gemma22b     3_Partial_hallucination             100.0\n",
      "3         gemma22b        4_Full_hallucination             100.0\n",
      "4   llama3.1latest          1_No_hallucination             100.0\n",
      "5   llama3.1latest       2_Small_hallucination             100.0\n",
      "6   llama3.1latest     3_Partial_hallucination             100.0\n",
      "7   llama3.1latest        4_Full_hallucination             100.0\n",
      "8        qwen2.53b          1_No_hallucination             100.0\n",
      "9        qwen2.53b       2_Small_hallucination             100.0\n",
      "10       qwen2.53b     3_Partial_hallucination             100.0\n",
      "11       qwen2.53b        4_Full_hallucination             100.0\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# Accuracy por clase\n",
    "# ---------------------\n",
    "# Definir si la predicci√≥n fue correcta\n",
    "df_all['correct_prediction'] = df_all['prediction_class'] == df_all['ground_truth_classification']\n",
    "\n",
    "# Agrupar por modelo, clase real y exactitud\n",
    "grouped = (\n",
    "    df_all.groupby(['model', 'ground_truth_classification', 'correct_prediction'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    ")\n",
    "\n",
    "# Calcular total por clase y modelo\n",
    "grouped['total'] = grouped.groupby(['model', 'ground_truth_classification'])['count'].transform('sum')\n",
    "\n",
    "# Calcular porcentaje\n",
    "grouped['percentage'] = (grouped['count'] / grouped['total']) * 100\n",
    "\n",
    "# Filtrar solo los aciertos (correct_prediction = True)\n",
    "accuracy_by_class = grouped[grouped['correct_prediction'] == True][[\n",
    "    'model', 'ground_truth_classification', 'percentage'\n",
    "]].rename(columns={'percentage': 'accuracy_percent'})\n",
    "\n",
    "# Mostrar resultados\n",
    "print(accuracy_by_class.sort_values(by=['model', 'ground_truth_classification']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
